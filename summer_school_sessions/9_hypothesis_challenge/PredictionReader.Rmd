---
title: "Prediction Reader"
author: "Alan Nielsen"
date: "September 20, 2017"
output: html_document
---

```{r Loading Libraries, message = FALSE, warning = FALSE}
library(tidyverse)
library(reshape2)
library(plyr)
library(doBy)
```

#Making Predictions
As part of the Hypothesis Challenge, you will be generating sets of hypotheses - you can do this in a few ways

You will be making predictions for how participants will respond for each type of comparison- thus the values you are predicting will be any number between 0 and 1.


A value of 0 suggests that the "High" Inducer goes with the "Low" Concurrent - for example on a Speed-Size Trial a response of 0 means that the participant chose that a Fast Object (Speed-H) is associated with A Small Figure (Size-L).

A value of 1 suggest that the "High" Inducer goes with the "High" concurrent- for example on a Pitch-Brightness trial a response of 1 means that the participant associated a High-Pitched sound (Pitch-H) with a Bright Image (Brightness-H).

You will not be making direct predictions about how participants respond on a trial-by-trial basis - instead you will be making a prediction about the *mean* value of participant responses for a given comparison. So you may think that on Pitch-Brightness Trials participants will **always** respond that High Pitch goes with Bright (and Low Pitch goes with Dark) - if that was your prediction you would give a value of "1" for that comparison.

It is unlikely, however, that all participants will *always* respond the same- so you're likely to want to make predictions that are a bit more moderate - you might predict for example that Participants will associate Brightness with High Pitch 90% of the time - in which case you would give a value of "0.9" for that comparison.

On the other hand, values close to "0" suggest that participants will match High-to-Low - so for Speed-Size comparisons you may think participants will generally think that Small Images are Fast - if you think *all* participants would respond in this way you could enter a value of "0", but you again might not want to make such a strong prediction - you might instead suggest that the mean Response will be "0.1", which would mean that on 90% of trials participants match Small to Fast.

A value of "0.5" means that participants responded randomly and/or had no bias to associate one domain with another - You might think that for comparisons between **Noise and Size** that participants might respond either way - that Small things are Noisy or that Large Things are noisy - here you might want to make a prediction around 0.5.

##Imputed Predictions

You are not required to make **every** prediction yourself - in fact you might argue that the most elegant explanation of the way participants respond is the one that makes the **minimum** number of predictions.

Earlier, Bill covered some scripts that Impute Predictions from seen values to unseen values - for example if we know (or have predicted) that participants will match Bright and High Pitched Stimuli 90% of the time (Predicted Mean Response = 0.9), and also that they will match Jagged and High Pitched Stimuli 80% of the time (Predicted Mean Response = 0.8), we can estimate that they will associate Bright and Jagged Stimuli 85% of the time (Predicted Mean Response = 0.85 - which is the average of the two known values).


##Assigning Predictions in Excel (Wide Format)

Maybe you find looking at the list of comparisons difficult, because you can't conceptualize how they are related to each other - the most natural way to look at the data is likely in wide format (this is also how we will visualise the data).

A set of predictions in wide format looks like this :

```{r Wide Format Predictions}
#### REPLACE THIS WITH YOUR EDITED FILE
myPWide <- read.csv("F:/Google Drive/GitHub Repos/ste-phen/summer_school_sessions/9_Hypothesis_Challenge/myPredictions-Wide-Sample.csv")

myPWide
```


You can look at the data frame here, but you can also look at it simply by opening it in Excel - to see our random set of associations open "myPredictions-Wide-Sample.csv". To make your own predictions, instead open "myPredictions-Wide.xls"

This spreadsheet is in .xls format because it includes some formulas that fill in values- the predictions you need to make are the empty cells in the top right of the data frame - once you make those predictions you can re-save the file - but re-save that file as "myPredictions-Wide.csv" noting that we want it in CSV format (not xls)

Once you've done that, you just need to get this data frame into the same format as myPredictions-Long - this Long Format dataframe is what will be used in Bill's Imputation Script, and also for the Simulation of data

To that end, you'll need to run the script below (don't worry about how it works- you will learn most of these commands tomorrow):

```{r Wide Format Data Transformation, message = FALSE, warning = FALSE}
colnames(myPWide) <- c("Inducer", "Affect EB", "Affect HS", "Affect PD", "Affect SC",
                       "Pitch", "Amplitude", "Noise", "Size", "Shape", "Speed", "Brightness",
                       "Color RB", "Color RG", "Color RY", "Color YB")

myPLong <- melt(myPWide,
                 variable.name = "Concurrent",
                value.name = "Prediction",
                 id.vars = "Inducer")

myPLong <- separate(data=myPLong, col= Inducer,     #split columns back up for subsetting
                         into= c("IndType", "IndToken"), sep = " ", remove = FALSE)
myPLong <- separate(data=myPLong, col= Concurrent, 
                         into= c("ConType", "ConToken"), sep = " ", remove = FALSE)

myPLong <- subset(myPLong, IndType != ConType)

# Code the comparison column into the SSData frame
myPLong$IndCon <- paste(myPLong$Inducer, myPLong$Concurrent, sep = '-')
myPLong$ConInd <- paste(myPLong$Inducer, myPLong$Concurrent, sep = '-')

myPLong$Comparison <- paste(myPLong$Inducer, myPLong$Concurrent, sep = '-') #Make a comparison column
myPLong <- arrange(myPLong, Comparison)  # Order the data frame alphabetically by the comparison column

delRows = NULL # the rows to be removed
for(i in 1:nrow(myPLong)){
  j = which(myPLong$Inducer == myPLong$Concurrent[i] & myPLong$Concurrent == myPLong$Inducer[i])
  j = j [j > i]
  if (length(j) > 0){
    delRows = c(delRows, j)
  }
}
myPLong <- myPLong[-delRows,]

myPLong <- subset(myPLong, select = c(Inducer, Concurrent, Comparison, Prediction))

write.csv(myPLong, "F:/Google Drive/GitHub Repos/ste-phen/summer_school_sessions/9_Hypothesis_Challenge/myPredictions-Long-YOURNAME.csv")

```

Just for fun, you can ouput a HeatMap of your Predictions:

```{r Predictions Heatmap}

myPLong <- read.csv("F:/Google Drive/GitHub Repos/ste-phen/summer_school_sessions/9_Hypothesis_Challenge/myPredictions-Long-YOURNAME.csv")

Predictions <- separate(data = myPLong, col = Comparison,
                      into = c("Left", "Right"), 
                      sep = "-", remove = FALSE)

Pred1 <- Predictions
Pred2 <- Predictions

Pred1$Inducer <- Pred1$Left
Pred1$Concurrent <- Pred1$Right

Pred2$Inducer <- Pred2$Right
Pred2$Concurrent <- Pred2$Left

Predictions <- rbind(Pred1, Pred2)

Predictions <- subset(Predictions, select = c("Inducer", "Concurrent", "Comparison", "Prediction"))

Domains <- sort(unique(Predictions$Inducer))
HighValues <- c("Excited/Bored", "Happy/Sad", "Pleased/Disgusted", "Stressed/Calm",
                "Loud/Quiet", "Bright/Dark", "Red/Blue", "Red/Green", "Red/Yellow",
                "Yellow/Blue", "Noisy/Tonal", "High Pitch/Low Pitch", "Jagged/Curvy", 
                "Large/Small", "Fast/Slow")

Predictions$Inducer2 <- mapvalues(Predictions$Inducer, from = Domains, to= HighValues)
Predictions$Concurrent2 <- mapvalues(Predictions$Concurrent, from = Domains, to= HighValues)

Predictions$Inducer2 <- factor(Predictions$Inducer2, 
                                  level = c("Excited/Bored", "Happy/Sad", "Pleased/Disgusted",
                                            "Stressed/Calm", "Loud/Quiet", "Bright/Dark", "Red/Blue",
                                            "Red/Green", "Red/Yellow", "Yellow/Blue", "Noisy/Tonal",
                                            "High Pitch/Low Pitch", "Jagged/Curvy", "Large/Small",
                                            "Fast/Slow"))

Predictions$Concurrent2 <- factor(Predictions$Concurrent2, 
                                  level = c("Excited/Bored", "Happy/Sad", "Pleased/Disgusted",
                                            "Stressed/Calm", "Loud/Quiet", "Bright/Dark", "Red/Blue",
                                            "Red/Green", "Red/Yellow", "Yellow/Blue", "Noisy/Tonal",
                                            "High Pitch/Low Pitch", "Jagged/Curvy", "Large/Small",
                                            "Fast/Slow"))

Predictions$Prediction <-as.numeric(Predictions$Prediction)


ggplot(data= Predictions, aes(x=Concurrent2, y=Inducer2, fill=Prediction)) +
  geom_tile(color = "white") +
  ggtitle("Biases - My Predictions") +
  scale_fill_gradient2(low = "red", high = "blue", mid = "white", 
                       midpoint = 0.5, limit = c(0,1),
                       name="Direction and Strength of Associaton") +
  theme_classic()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))+
  coord_fixed() 

```


So that is your grpah of your predictions - anything that is pure white you haven't provided a prediction for

You can now take that data frame and use it to impute the predictions that you did not provide - to do this you will use the notebook from Bill (Predict and Simulate.ipynb)- once you have imputed your missing values, come back to this Markdown Document!

------------------------------------------------

Okay so you've now got a file called "MyImputedPredictions.csv" - we can load that in and output an additional heatmap with our new imputed predictions:


```{r Heatmap of Imputed Predictions}

ImputedPredictions <- read.csv("F:/Google Drive/GitHub Repos/ste-phen/summer_school_sessions/9_Hypothesis_Challenge/MyImputedPredictions.csv")

ImputedPredictions <- subset(ImputedPredictions, select = c(Comparison, ImputedPrediction))

ImputedPredictions <- separate(data = ImputedPredictions, col = Comparison,
                      into = c("Left", "Right"), 
                      sep = "-", remove = FALSE)

Pred1 <- ImputedPredictions
Pred2 <- ImputedPredictions

Pred1$Inducer <- Pred1$Left
Pred1$Concurrent <- Pred1$Right

Pred2$Inducer <- Pred2$Right
Pred2$Concurrent <- Pred2$Left

ImputedPredictions <- rbind(Pred1, Pred2)


Domains <- sort(unique(ImputedPredictions$Inducer))
HighValues <- c("Excited/Bored", "Happy/Sad", "Pleased/Disgusted", "Stressed/Calm",
                "Loud/Quiet", "Bright/Dark", "Red/Blue", "Red/Green", "Red/Yellow",
                "Yellow/Blue", "Noisy/Tonal", "High Pitch/Low Pitch", "Jagged/Curvy", 
                "Large/Small", "Fast/Slow")

ImputedPredictions$Inducer2 <- mapvalues(ImputedPredictions$Inducer, from = Domains, to= HighValues)
ImputedPredictions$Concurrent2 <- mapvalues(ImputedPredictions$Concurrent, from = Domains, to= HighValues)

ImputedPredictions$Inducer2 <- factor(ImputedPredictions$Inducer2, 
                                  level = c("Excited/Bored", "Happy/Sad", "Pleased/Disgusted",
                                            "Stressed/Calm", "Loud/Quiet", "Bright/Dark", "Red/Blue",
                                            "Red/Green", "Red/Yellow", "Yellow/Blue", "Noisy/Tonal",
                                            "High Pitch/Low Pitch", "Jagged/Curvy", "Large/Small",
                                            "Fast/Slow"))

ImputedPredictions$Concurrent2 <- factor(ImputedPredictions$Concurrent2, 
                                  level = c("Excited/Bored", "Happy/Sad", "Pleased/Disgusted",
                                            "Stressed/Calm", "Loud/Quiet", "Bright/Dark", "Red/Blue",
                                            "Red/Green", "Red/Yellow", "Yellow/Blue", "Noisy/Tonal",
                                            "High Pitch/Low Pitch", "Jagged/Curvy", "Large/Small",
                                            "Fast/Slow"))



ggplot(data= ImputedPredictions, aes(x=Concurrent2, y=Inducer2, fill=ImputedPrediction)) +
  geom_tile(color = "white") +
  ggtitle("Biases - My Imputed Predictions") +
  scale_fill_gradient2(low = "red", high = "blue", mid = "white", 
                       midpoint = 0.5, limit = c(0,1),
                       name="Direction and Strength of Associaton") +
  theme_classic()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))+
  coord_fixed() 

```


So above is your plot from your Imputed Predictions- this is just a plot of the means that you supplied.

The last plot that we can sensibly produce is a plot of associations from your SIMULATED data


```{r Heatmap from SimData}

simdata <- read.csv("F:/Google Drive/GitHub Repos/ste-phen/summer_school_sessions/9_Hypothesis_Challenge/SimDataFilled.csv")

simdataAgg <- summaryBy(ResponseSimulated ~ 
                       DataSet + Inducer + Concurrent + Comparison,
                     data= simdata, Fun = c(mean))

Domains <- sort(unique(simdataAgg$Inducer))
HighValues <- c("Excited/Bored", "Happy/Sad", "Pleased/Disgusted", "Stressed/Calm",
                "Loud/Quiet", "Bright/Dark", "Red/Blue", "Red/Green", "Red/Yellow",
                "Yellow/Blue", "Noisy/Tonal", "High Pitch/Low Pitch", "Jagged/Curvy", 
                "Large/Small", "Fast/Slow")

simdataAgg$Inducer2 <- mapvalues(simdataAgg$Inducer, from = Domains, to= HighValues)
simdataAgg$Concurrent2 <- mapvalues(simdataAgg$Concurrent, from = Domains, to= HighValues)

ggplot(data= simdataAgg, aes(x=Concurrent2, y=Inducer2, fill=ResponseSimulated.mean)) +
  geom_tile(color = "white") +
  ggtitle("Biases - Simulated Data") +
  scale_fill_gradient2(low = "red", high = "blue", mid = "white", 
                       midpoint = 0.5, limit = c(0,1),
                       name="Direction and Strength of Associaton") +
  theme_classic()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))+
  coord_fixed() 

```


So those are your graphs - to drive the difference between them home, one quite sensible thing we can do is just to plot them all in one plot with facet_wrap (which involves first collapsing all of the data into a single dataframe)


```{r One Heatplot to Rule them all and in the darkness bind them}

Predictions <- arrange(Predictions, Comparison)
ImputedPredictions <- arrange(ImputedPredictions, Comparison)
simdataAgg <- arrange(simdataAgg, Comparison)

TheOne <- subset(Predictions, select = c(Inducer2, Concurrent2, Prediction))
TheOne$ImputedPrediction <- ImputedPredictions$ImputedPrediction
TheOne$SimData <- simdataAgg$ResponseSimulated.mean

TheOne <- melt(TheOne,
                   variable.name = "Source",
                   id.vars = c ("Inducer2", "Concurrent2"))

ggplot(data= TheOne, aes(x=Concurrent2, y=Inducer2, fill=value)) +
  geom_tile(color = "white") +
  ggtitle("Biases - Affect Data") +
  scale_fill_gradient2(low = "red", high = "blue", mid = "white", 
                       midpoint = 0.5, limit = c(0,1),
                       name="Direction and Strength of Associaton") +
  theme_classic()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))+
  facet_wrap(~Source, nrow =3)
  coord_fixed()


```





